"""
Streamlit æœºå™¨å­¦ä¹ åŠŸèƒ½æ¨¡å—
æä¾›æ¨¡å‹è®­ç»ƒå’Œæ™ºèƒ½å‚æ•°ä¼˜åŒ–çš„å®Œæ•´é¡µé¢åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import io
import time
from datetime import datetime, timedelta
import plotly.graph_objects as go

# æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
TORCH_AVAILABLE = False
LIGHTGBM_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    pass

try:
    import lightgbm
    LIGHTGBM_AVAILABLE = True
except ImportError:
    pass


# ==================== å‚æ•°é™åˆ¶å¸¸é‡ï¼ˆä¸æ¨¡å‹ä¿æŒä¸€è‡´ï¼‰====================

PARAM_LIMITS = {
    # åˆ©æ¶¦å‚æ•°é™åˆ¶ (å…ƒ/å‡)
    'profits': {
        'ç¢³é…¸é¥®æ–™': (5.0, 15.0),
        'æœæ±é¥®æ–™': (8.0, 18.0),
        'èŒ¶é¥®æ–™': (6.0, 16.0),
        'åŠŸèƒ½é¥®æ–™': (10.0, 25.0),
        'çŸ¿æ³‰æ°´': (3.0, 10.0),
    },
    # åŸæ–™ä¾›åº”é™åˆ¶ (åƒå…‹)
    'material_limits': {
        'ç™½ç ‚ç³–': (8000, 25000),
        'æµ“ç¼©æœæ±': (4000, 15000),
        'èŒ¶å¶æå–ç‰©': (3000, 12000),
        'åŠŸèƒ½æˆåˆ†': (1000, 5000),
        'åŒ…è£…ææ–™': (8000, 20000),
    },
    # è¿è¾“èƒ½åŠ›é™åˆ¶ (å‡)
    'transport_limits': {
        'é“é‡ŒåŒº': (2000, 5000),
        'å—å²—åŒº': (1500, 4000),
        'é“å¤–åŒº': (1200, 3500),
        'é¦™åŠåŒº': (1000, 3000),
        'æ¾åŒ—åŒº': (600, 2000),
    },
    # ç”Ÿäº§çº¦æŸå‚æ•°
    'min_production_ratio': (0.5, 0.95),
    'max_production_multiplier': (1.2, 2.5),
}


# ==================== æ•°æ®æ¨¡æ¿ç”Ÿæˆ ====================

def generate_transformer_template():
    """ç”Ÿæˆ Transformer è®­ç»ƒæ•°æ®æ¨¡æ¿ - åŒ…å«å„åœ°åŒºé”€å”®æ•°æ®"""
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆ30å¤©ï¼Œ5ç§é¥®æ–™ï¼Œ5ä¸ªåœ°åŒºï¼‰
    dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
    np.random.seed(42)

    # åœ°åŒºåˆ—è¡¨
    regions = ['é“é‡ŒåŒº', 'å—å²—åŒº', 'é“å¤–åŒº', 'é¦™åŠåŒº', 'æ¾åŒ—åŒº']
    beverages = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']

    # å„é¥®æ–™åœ¨å„åœ°åŒºçš„åŸºç¡€é”€é‡èŒƒå›´
    base_sales = {
        'ç¢³é…¸é¥®æ–™': {'é“é‡ŒåŒº': (400, 550), 'å—å²—åŒº': (500, 650), 'é“å¤–åŒº': (350, 480), 'é¦™åŠåŒº': (280, 400), 'æ¾åŒ—åŒº': (180, 280)},
        'æœæ±é¥®æ–™': {'é“é‡ŒåŒº': (280, 380), 'å—å²—åŒº': (420, 550), 'é“å¤–åŒº': (320, 420), 'é¦™åŠåŒº': (200, 300), 'æ¾åŒ—åŒº': (80, 150)},
        'èŒ¶é¥®æ–™': {'é“é‡ŒåŒº': (320, 420), 'å—å²—åŒº': (280, 380), 'é“å¤–åŒº': (220, 320), 'é¦™åŠåŒº': (200, 300), 'æ¾åŒ—åŒº': (60, 120)},
        'åŠŸèƒ½é¥®æ–™': {'é“é‡ŒåŒº': (200, 300), 'å—å²—åŒº': (180, 280), 'é“å¤–åŒº': (120, 200), 'é¦™åŠåŒº': (60, 120), 'æ¾åŒ—åŒº': (30, 70)},
        'çŸ¿æ³‰æ°´': {'é“é‡ŒåŒº': (350, 480), 'å—å²—åŒº': (550, 700), 'é“å¤–åŒº': (600, 780), 'é¦™åŠåŒº': (400, 550), 'æ¾åŒ—åŒº': (200, 350)},
    }

    data = {'æ—¥æœŸ': dates.strftime('%Y-%m-%d')}

    # ä¸ºæ¯ä¸ªé¥®æ–™çš„æ¯ä¸ªåœ°åŒºç”Ÿæˆé”€å”®æ•°æ®
    for bev in beverages:
        for region in regions:
            col_name = f'{bev}_{region}'
            low, high = base_sales[bev][region]
            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨å’Œè¶‹åŠ¿
            base = np.random.uniform(low, high, 30)
            # æ·»åŠ å‘¨æœ«æ•ˆåº”ï¼ˆå‘¨å…­æ—¥é”€é‡å¢åŠ 10-20%ï¼‰
            weekend_mask = np.array([d.weekday() >= 5 for d in dates])
            base[weekend_mask] *= np.random.uniform(1.1, 1.2, weekend_mask.sum())
            data[col_name] = base.astype(int)

    # æ·»åŠ å„é¥®æ–™çš„æ€»é”€é‡åˆ—ï¼ˆå¯é€‰ï¼Œä¾¿äºæŸ¥çœ‹ï¼‰
    df = pd.DataFrame(data)
    for bev in beverages:
        bev_cols = [f'{bev}_{r}' for r in regions]
        df[f'{bev}_æ€»è®¡'] = df[bev_cols].sum(axis=1)

    return df


def generate_lightgbm_template():
    """ç”Ÿæˆ LightGBM è®­ç»ƒæ•°æ®æ¨¡æ¿ - åŒ…å«è¯¦ç»†åœºæ™¯ç´¢å¼•ï¼Œå‚æ•°ä¸¥æ ¼åœ¨æ¨¡å‹é™åˆ¶èŒƒå›´å†…"""
    np.random.seed(42)
    n_samples = 10  # ç¤ºä¾‹10æ¡

    # ç”Ÿæˆæœ‰æ„ä¹‰çš„åœºæ™¯ç´¢å¼•
    scenarios = [
        '2024å¹´1æœˆ_æ˜¥èŠ‚å‰æ—ºå­£',
        '2024å¹´2æœˆ_æ˜¥èŠ‚æœŸé—´',
        '2024å¹´3æœˆ_èŠ‚åæ·¡å­£',
        '2024å¹´4æœˆ_æ˜¥å­£ä¿ƒé”€',
        '2024å¹´5æœˆ_åŠ³åŠ¨èŠ‚æ¡£æœŸ',
        '2024å¹´6æœˆ_å¤å­£å¼€å§‹',
        '2024å¹´7æœˆ_æš‘æœŸæ—ºå­£',
        '2024å¹´8æœˆ_é«˜æ¸©æœŸ',
        '2024å¹´9æœˆ_å¼€å­¦å­£',
        '2024å¹´10æœˆ_å›½åº†æ¡£æœŸ',
    ]

    # åœ°åŒºåˆ—è¡¨
    regions = ['é“é‡ŒåŒº', 'å—å²—åŒº', 'é“å¤–åŒº', 'é¦™åŠåŒº', 'æ¾åŒ—åŒº']
    beverages = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']
    materials = ['ç™½ç ‚ç³–', 'æµ“ç¼©æœæ±', 'èŒ¶å¶æå–ç‰©', 'åŠŸèƒ½æˆåˆ†', 'åŒ…è£…ææ–™']

    data = {'åœºæ™¯': scenarios}

    # è¾“å…¥ç‰¹å¾ï¼šå„é¥®æ–™å„åœ°åŒºçš„7å¤©é¢„æµ‹é”€é‡æ±‡æ€»
    sales_ranges = {
        'ç¢³é…¸é¥®æ–™': (12000, 18000),
        'æœæ±é¥®æ–™': (9000, 14000),
        'èŒ¶é¥®æ–™': (7000, 11000),
        'åŠŸèƒ½é¥®æ–™': (4000, 8000),
        'çŸ¿æ³‰æ°´': (15000, 22000),
    }

    for bev in beverages:
        low, high = sales_ranges[bev]
        data[f'{bev}_7å¤©æ€»é”€é‡'] = np.random.uniform(low, high, n_samples).astype(int)

        # å„åœ°åŒºé”€é‡å æ¯”ç‰¹å¾
        for region in regions:
            data[f'{bev}_{region}_å æ¯”'] = np.random.uniform(0.1, 0.35, n_samples).round(2)

    # æ·»åŠ è¶‹åŠ¿ç‰¹å¾
    data['æ•´ä½“é”€é‡è¶‹åŠ¿'] = np.random.choice(['ä¸Šå‡', 'å¹³ç¨³', 'ä¸‹é™'], n_samples)
    data['å­£èŠ‚æ€§å› å­'] = np.random.uniform(0.8, 1.3, n_samples).round(2)

    # è¾“å‡ºæ ‡ç­¾ï¼šæ¨èå‚æ•°ï¼ˆä¸¥æ ¼ä½¿ç”¨ PARAM_LIMITS ä¸­çš„èŒƒå›´ï¼‰
    # åˆ©æ¶¦å‚æ•°
    for bev in beverages:
        low, high = PARAM_LIMITS['profits'][bev]
        data[f'{bev}_æ¨èåˆ©æ¶¦'] = np.random.uniform(low, high, n_samples).round(1)

    # åŸæ–™ä¾›åº”é™åˆ¶
    for mat in materials:
        low, high = PARAM_LIMITS['material_limits'][mat]
        data[f'{mat}_ä¾›åº”é™åˆ¶'] = np.random.uniform(low, high, n_samples).astype(int)

    # è¿è¾“èƒ½åŠ›é™åˆ¶
    for region in regions:
        low, high = PARAM_LIMITS['transport_limits'][region]
        data[f'{region}_è¿è¾“é™åˆ¶'] = np.random.uniform(low, high, n_samples).astype(int)

    # ç”Ÿäº§çº¦æŸå‚æ•°ï¼ˆä½¿ç”¨ PARAM_LIMITS ä¸­çš„èŒƒå›´ï¼‰
    min_low, min_high = PARAM_LIMITS['min_production_ratio']
    max_low, max_high = PARAM_LIMITS['max_production_multiplier']
    data['æœ€å°ç”Ÿäº§æ¯”ä¾‹'] = np.random.uniform(min_low, min_high, n_samples).round(2)
    data['æœ€å¤§ç”Ÿäº§å€æ•°'] = np.random.uniform(max_low, max_high, n_samples).round(1)

    df = pd.DataFrame(data)
    df = df.set_index('åœºæ™¯')

    return df


def convert_df_to_csv(df, include_index=False):
    """å°† DataFrame è½¬æ¢ä¸º CSV å­—èŠ‚æµ"""
    return df.to_csv(index=include_index, encoding='utf-8-sig').encode('utf-8-sig')


def clip_params_to_limits(params_dict):
    """å°†é¢„æµ‹çš„å‚æ•°è£å‰ªåˆ°æ¨¡å‹å…è®¸çš„èŒƒå›´å†…"""
    clipped = {}

    beverages = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']
    materials = ['ç™½ç ‚ç³–', 'æµ“ç¼©æœæ±', 'èŒ¶å¶æå–ç‰©', 'åŠŸèƒ½æˆåˆ†', 'åŒ…è£…ææ–™']
    regions = ['é“é‡ŒåŒº', 'å—å²—åŒº', 'é“å¤–åŒº', 'é¦™åŠåŒº', 'æ¾åŒ—åŒº']

    # è£å‰ªåˆ©æ¶¦å‚æ•°
    clipped['profits'] = {}
    for bev in beverages:
        low, high = PARAM_LIMITS['profits'][bev]
        val = params_dict.get('profits', {}).get(bev, (low + high) / 2)
        clipped['profits'][bev] = round(max(low, min(high, val)), 1)

    # è£å‰ªåŸæ–™ä¾›åº”é™åˆ¶
    clipped['material_limits'] = {}
    for mat in materials:
        low, high = PARAM_LIMITS['material_limits'][mat]
        val = params_dict.get('material_limits', {}).get(mat, (low + high) / 2)
        clipped['material_limits'][mat] = int(max(low, min(high, val)))

    # è£å‰ªè¿è¾“èƒ½åŠ›é™åˆ¶
    clipped['transport_limits'] = {}
    for region in regions:
        low, high = PARAM_LIMITS['transport_limits'][region]
        val = params_dict.get('transport_limits', {}).get(region, (low + high) / 2)
        clipped['transport_limits'][region] = int(max(low, min(high, val)))

    # è£å‰ªç”Ÿäº§çº¦æŸå‚æ•°
    min_low, min_high = PARAM_LIMITS['min_production_ratio']
    max_low, max_high = PARAM_LIMITS['max_production_multiplier']

    min_ratio = params_dict.get('min_production_ratio', (min_low + min_high) / 2)
    max_mult = params_dict.get('max_production_multiplier', (max_low + max_high) / 2)

    clipped['min_production_ratio'] = round(max(min_low, min(min_high, min_ratio)), 2)
    clipped['max_production_multiplier'] = round(max(max_low, min(max_high, max_mult)), 1)

    return clipped


# ==================== é¡µé¢çŠ¶æ€ç®¡ç† ====================

def init_session_state():
    """åˆå§‹åŒ– session state"""
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 'main'
    if 'training_model_expanded' not in st.session_state:
        st.session_state.training_model_expanded = False
    if 'recommendations' not in st.session_state:
        st.session_state.recommendations = None
    if 'sync_params' not in st.session_state:
        st.session_state.sync_params = False


def check_model_status():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶çŠ¶æ€"""
    try:
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        base_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.join(base_dir, 'data')

        return {
            'transformer_model': os.path.exists(os.path.join(data_dir, 'best_transformer_model.pth')),
            'transformer_scaler': os.path.exists(os.path.join(data_dir, 'scaler_params.npz')),
            'lightgbm_model': os.path.exists(os.path.join(data_dir, 'lgb_meta.joblib')),
        }
    except Exception:
        # å¦‚æœå‡ºç°ä»»ä½•é”™è¯¯ï¼Œè¿”å›å…¨éƒ¨ä¸º False
        return {
            'transformer_model': False,
            'transformer_scaler': False,
            'lightgbm_model': False,
        }


# ==================== ä¾§è¾¹æ å¯¼èˆª ====================

def sidebar_navigation():
    """ä¾§è¾¹æ å¯¼èˆªèœå•"""
    st.sidebar.markdown("---")
    st.sidebar.markdown("## ğŸš€ é«˜çº§åŠŸèƒ½")

    # æ¨¡å‹è®­ç»ƒ - å¯å±•å¼€çš„å­é€‰é¡¹
    with st.sidebar.expander("ğŸ“ æ¨¡å‹è®­ç»ƒ", expanded=st.session_state.get('training_model_expanded', False)):
        st.caption("è®­ç»ƒæ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æ¨¡å‹")

        if st.button("ğŸ¤– Transformer è®­ç»ƒ", key="nav_transformer", use_container_width=True):
            st.session_state.current_page = 'transformer_training'
            st.session_state.training_model_expanded = True
            st.rerun()

        if st.button("ğŸ“Š LightGBM è®­ç»ƒ", key="nav_lightgbm", use_container_width=True):
            st.session_state.current_page = 'lightgbm_training'
            st.session_state.training_model_expanded = True
            st.rerun()

        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        status = check_model_status()
        st.markdown("---")
        st.markdown("**æ¨¡å‹çŠ¶æ€:**")
        transformer_status = "âœ… å·²è®­ç»ƒ" if status['transformer_model'] else "âšª æœªè®­ç»ƒ"
        lightgbm_status = "âœ… å·²è®­ç»ƒ" if status['lightgbm_model'] else "âšª æœªè®­ç»ƒ"
        st.caption(f"Transformer: {transformer_status}")
        st.caption(f"LightGBM: {lightgbm_status}")

    # æ™ºèƒ½å‚æ•°ä¼˜åŒ–
    if st.sidebar.button("ğŸ§  æ™ºèƒ½å‚æ•°ä¼˜åŒ–", key="nav_smart_opt", use_container_width=True):
        st.session_state.current_page = 'smart_optimization'
        st.rerun()

    # è¿”å›ä¸»é¡µ
    if st.session_state.current_page != 'main':
        st.sidebar.markdown("---")
        if st.sidebar.button("ğŸ  è¿”å›ä¸»é¡µ", key="nav_home", use_container_width=True):
            st.session_state.current_page = 'main'
            st.rerun()


# ==================== Transformer è®­ç»ƒé¡µé¢ ====================

def page_transformer_training():
    """Transformer æ¨¡å‹è®­ç»ƒé¡µé¢"""
    st.markdown("# ğŸ¤– Transformer é”€å”®é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    st.markdown("---")

    # æ£€æŸ¥ PyTorch æ˜¯å¦å¯ç”¨
    if not TORCH_AVAILABLE:
        st.warning("âš ï¸ PyTorch æœªå®‰è£…ï¼Œæ— æ³•è®­ç»ƒ Transformer æ¨¡å‹")
        st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š`pip install torch`")
        st.markdown("---")
        st.markdown("### ğŸ’¡ æç¤º")
        st.markdown("å®‰è£… PyTorch ååˆ·æ–°é¡µé¢å³å¯ä½¿ç”¨è®­ç»ƒåŠŸèƒ½ã€‚")
        return

    # æ¨¡å‹ä»‹ç»
    with st.container():
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;">
            <h3>ğŸ“Œ æ¨¡å‹è¯´æ˜</h3>
            <p><strong>ç”¨é€”ï¼š</strong>åŸºäºå†å²é”€å”®æ•°æ®ï¼Œé¢„æµ‹æœªæ¥7å¤©å„é¥®æ–™çš„é”€é‡</p>
            <p><strong>è¾“å…¥ï¼š</strong>è¿‡å»30å¤©çš„5ç§é¥®æ–™é”€å”®æ•°æ®</p>
            <p><strong>è¾“å‡ºï¼š</strong>æœªæ¥7å¤©çš„é”€å”®é¢„æµ‹</p>
            <p><strong>åº”ç”¨åœºæ™¯ï¼š</strong>ç”Ÿäº§è®¡åˆ’åˆ¶å®šã€åŸæ–™é‡‡è´­è§„åˆ’ã€è¿è¾“è°ƒåº¦å®‰æ’</p>
        </div>
        """, unsafe_allow_html=True)

    # æ•°æ®æ¥æºé€‰æ‹©
    st.markdown("### ğŸ“Š é€‰æ‹©æ•°æ®æ¥æº")
    data_source = st.radio(
        "è¯·é€‰æ‹©è®­ç»ƒæ•°æ®æ¥æºï¼š",
        ["ğŸ² ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®", "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®"],
        key="transformer_data_source",
        horizontal=True
    )

    col1, col2 = st.columns([2, 1])

    with col1:
        if data_source == "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®":
            # æ•°æ®ä¸Šä¼ åŒºåŸŸ
            st.markdown("### ğŸ“ ä¸Šä¼ è®­ç»ƒæ•°æ®")
            st.info("""
            **æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
            - CSV æ–‡ä»¶æ ¼å¼
            - å¿…é¡»åŒ…å«åˆ—ï¼šæ—¥æœŸ + å„é¥®æ–™å„åœ°åŒºé”€é‡
            - åˆ—åæ ¼å¼ï¼š`é¥®æ–™å_åœ°åŒºå`ï¼ˆå¦‚ï¼šç¢³é…¸é¥®æ–™_é“é‡ŒåŒºï¼‰
            - åœ°åŒºï¼šé“é‡ŒåŒºã€å—å²—åŒºã€é“å¤–åŒºã€é¦™åŠåŒºã€æ¾åŒ—åŒº
            - é¥®æ–™ï¼šç¢³é…¸é¥®æ–™ã€æœæ±é¥®æ–™ã€èŒ¶é¥®æ–™ã€åŠŸèƒ½é¥®æ–™ã€çŸ¿æ³‰æ°´
            - é”€é‡å•ä½ï¼šå‡
            - å»ºè®®è‡³å°‘ 365 å¤©æ•°æ®
            """)

            uploaded_file = st.file_uploader(
                "é€‰æ‹© CSV æ–‡ä»¶ä¸Šä¼ ",
                type=['csv'],
                key="transformer_upload",
                help="ä¸Šä¼ åŒ…å«å†å²é”€å”®æ•°æ®çš„ CSV æ–‡ä»¶"
            )

            # æ˜¾ç¤ºä¸Šä¼ çš„æ•°æ®é¢„è§ˆ
            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                    st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")
                    st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                    st.dataframe(df.head(10), use_container_width=True)
                    st.session_state['transformer_data'] = df
                    st.session_state['transformer_data_ready'] = True
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
                    st.session_state['transformer_data_ready'] = False
            else:
                st.warning("âš ï¸ è¯·ä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶")
                st.session_state['transformer_data_ready'] = False

        else:  # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            st.markdown("### ğŸ² æ¨¡æ‹Ÿæ•°æ®è®¾ç½®")
            st.info("ç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆç¬¦åˆæ¨¡å‹è¦æ±‚çš„æ¨¡æ‹Ÿé”€å”®æ•°æ®ç”¨äºè®­ç»ƒã€‚")

            data_days = st.slider("ç”Ÿæˆæ•°æ®å¤©æ•°", 365, 1095, 730, 365, key="t_data_days")

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
            if 'transformer_data' in st.session_state and st.session_state.get('transformer_data_source_type') == 'simulated':
                st.success(f"âœ… å·²å‡†å¤‡ {len(st.session_state['transformer_data'])} å¤©çš„æ¨¡æ‹Ÿæ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(st.session_state['transformer_data'].head(10), use_container_width=True)

            if st.button("ğŸ”„ é¢„è§ˆ/åˆ·æ–°æ¨¡æ‹Ÿæ•°æ®", key="preview_transformer_data"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®..."):
                    from sales_data_processor import SalesDataGenerator
                    generator = SalesDataGenerator()
                    df = generator.generate_sales_data(num_days=data_days)
                    st.session_state['transformer_data'] = df
                    st.session_state['transformer_data_source_type'] = 'simulated'
                    st.session_state['transformer_data_days'] = data_days
                    st.rerun()

            # æ¨¡æ‹Ÿæ•°æ®å§‹ç»ˆå¯ç”¨
            st.session_state['transformer_data_ready'] = True

    with col2:
        # ä¸‹è½½æ¨¡æ¿
        st.markdown("### ğŸ“¥ æ•°æ®æ¨¡æ¿ä¸‹è½½")
        template_df = generate_transformer_template()
        csv_data = convert_df_to_csv(template_df)

        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½æ•°æ®æ¨¡æ¿",
            data=csv_data,
            file_name="transformer_data_template.csv",
            mime="text/csv",
            use_container_width=True
        )

        st.markdown("**æ¨¡æ¿é¢„è§ˆï¼š**")
        st.dataframe(template_df.head(5), use_container_width=True)

        # è®­ç»ƒå‚æ•°
        st.markdown("### âš™ï¸ è®­ç»ƒå‚æ•°")
        epochs = st.number_input("è®­ç»ƒè½®æ•°", 10, 200, 50, 10, key="t_epochs")
        batch_size = st.selectbox("æ‰¹æ¬¡å¤§å°", [16, 32, 64], index=1, key="t_batch")
        learning_rate = st.select_slider("å­¦ä¹ ç‡", [0.0001, 0.0005, 0.001, 0.005], value=0.001, key="t_lr")

    # å¼€å§‹è®­ç»ƒæŒ‰é’®
    st.markdown("---")
    st.markdown("### ğŸš€ å¼€å§‹è®­ç»ƒ")

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ¯ å¼€å§‹è®­ç»ƒ Transformer æ¨¡å‹", key="start_transformer_training",
                     use_container_width=True, type="primary"):
            if not TORCH_AVAILABLE:
                st.error("âŒ PyTorch æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install torch")
            elif data_source == "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®":
                # ä½¿ç”¨ä¸Šä¼ æ•°æ®æ¨¡å¼
                if not st.session_state.get('transformer_data_ready', False) or 'transformer_data' not in st.session_state:
                    st.error("âŒ è¯·å…ˆä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶")
                else:
                    train_transformer_with_progress(
                        st.session_state['transformer_data'],
                        epochs, batch_size, learning_rate
                    )
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ - è‡ªåŠ¨ç”Ÿæˆæ•°æ®
                with st.spinner("æ­£åœ¨å‡†å¤‡æ¨¡æ‹Ÿæ•°æ®..."):
                    from sales_data_processor import SalesDataGenerator
                    generator = SalesDataGenerator()
                    data_days = st.session_state.get('transformer_data_days', 730)
                    df = generator.generate_sales_data(num_days=data_days)
                    st.session_state['transformer_data'] = df
                    st.session_state['transformer_data_source_type'] = 'simulated'
                train_transformer_with_progress(df, epochs, batch_size, learning_rate)


def train_transformer_with_progress(df, epochs, batch_size, learning_rate):
    """å¸¦è¿›åº¦æ¡çš„ Transformer è®­ç»ƒ"""
    import torch
    import torch.nn as nn
    import copy

    from transformer_model import SalesForecasterEncoderOnly
    from sales_data_processor import SalesDataProcessor, create_data_loaders

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    st.markdown("### ğŸ“ˆ è®­ç»ƒè¿›åº¦")
    progress_container = st.container()

    with progress_container:
        status_text = st.empty()
        progress_bar = st.progress(0)
        metrics_placeholder = st.empty()
        chart_placeholder = st.empty()

    try:
        status_text.info("ğŸ”„ å‡†å¤‡æ•°æ®ä¸­...")

        # ä¿å­˜åŸå§‹æ•°æ®
        os.makedirs('./data', exist_ok=True)
        df.to_csv('./data/sales_data.csv', index=False, encoding='utf-8-sig')

        # æå–é”€å”®æ•°æ®
        beverage_cols = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']
        sales_values = df[beverage_cols].values

        # æ•°æ®é¢„å¤„ç†
        processor = SalesDataProcessor()
        normalized_data = processor.fit_transform(sales_values)
        processor.save_scaler('./data/scaler_params.npz')

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, _ = create_data_loaders(
            normalized_data, input_seq_len=30, output_seq_len=7, batch_size=batch_size
        )

        status_text.info("ğŸ”„ åˆå§‹åŒ–æ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹
        model = SalesForecasterEncoderOnly(
            input_dim=5, d_model=128, num_heads=8, num_layers=4,
            d_ff=512, input_seq_len=30, output_seq_len=7, dropout=0.1
        ).to(device)

        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.MSELoss()

        best_loss = float('inf')
        best_model_wts = copy.deepcopy(model.state_dict())

        # è®°å½•è®­ç»ƒå†å²
        train_losses = []
        val_losses = []

        status_text.info("ğŸš€ å¼€å§‹è®­ç»ƒ...")

        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            for b_x, b_y in train_loader:
                b_x, b_y = b_x.to(device), b_y.to(device)
                output = model(b_x)
                loss = criterion(output, b_y)
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                train_loss += loss.item()

            train_loss /= len(train_loader)
            train_losses.append(train_loss)

            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for b_x, b_y in val_loader:
                    b_x, b_y = b_x.to(device), b_y.to(device)
                    output = model(b_x)
                    val_loss += criterion(output, b_y).item()

            val_loss /= len(val_loader)
            val_losses.append(val_loss)

            if val_loss < best_loss:
                best_loss = val_loss
                best_model_wts = copy.deepcopy(model.state_dict())

            # æ›´æ–°è¿›åº¦
            progress = (epoch + 1) / epochs
            progress_bar.progress(progress)

            # æ›´æ–°æŒ‡æ ‡æ˜¾ç¤º
            metrics_placeholder.markdown(f"""
            **å½“å‰è¿›åº¦ï¼š** Epoch {epoch + 1}/{epochs}

            | æŒ‡æ ‡ | è®­ç»ƒé›† | éªŒè¯é›† |
            |------|--------|--------|
            | Loss | {train_loss:.6f} | {val_loss:.6f} |
            | æœ€ä½³ Val Loss | {best_loss:.6f} | - |
            """)

            # æ›´æ–°æŸå¤±æ›²çº¿
            if (epoch + 1) % 5 == 0 or epoch == epochs - 1:
                fig = go.Figure()
                fig.add_trace(go.Scatter(y=train_losses, mode='lines', name='è®­ç»ƒæŸå¤±'))
                fig.add_trace(go.Scatter(y=val_losses, mode='lines', name='éªŒè¯æŸå¤±'))
                fig.update_layout(
                    title="è®­ç»ƒæŸå¤±æ›²çº¿",
                    xaxis_title="Epoch",
                    yaxis_title="Loss",
                    height=300
                )
                chart_placeholder.plotly_chart(fig, use_container_width=True)

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        torch.save(best_model_wts, './data/best_transformer_model.pth')

        status_text.empty()
        progress_bar.empty()

        st.success(f"""
        âœ… **è®­ç»ƒå®Œæˆï¼**
        - æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}
        - æ¨¡å‹å·²ä¿å­˜è‡³: ./data/best_transformer_model.pth
        """)
        st.balloons()

    except Exception as e:
        st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")


# ==================== LightGBM è®­ç»ƒé¡µé¢ ====================

def page_lightgbm_training():
    """LightGBM æ¨¡å‹è®­ç»ƒé¡µé¢"""
    st.markdown("# ğŸ“Š LightGBM å‚æ•°æ¨èæ¨¡å‹è®­ç»ƒ")
    st.markdown("---")

    # æ£€æŸ¥ LightGBM æ˜¯å¦å¯ç”¨
    if not LIGHTGBM_AVAILABLE:
        st.warning("âš ï¸ LightGBM æœªå®‰è£…ï¼Œæ— æ³•è®­ç»ƒå‚æ•°æ¨èæ¨¡å‹")
        st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š`pip install lightgbm`")
        st.markdown("---")
        st.markdown("### ğŸ’¡ æç¤º")
        st.markdown("å®‰è£… LightGBM ååˆ·æ–°é¡µé¢å³å¯ä½¿ç”¨è®­ç»ƒåŠŸèƒ½ã€‚")
        return

    # æ¨¡å‹ä»‹ç»
    with st.container():
        st.markdown("""
        <div style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
                    padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;">
            <h3>ğŸ“Œ æ¨¡å‹è¯´æ˜</h3>
            <p><strong>ç”¨é€”ï¼š</strong>æ ¹æ®é”€å”®é¢„æµ‹æ•°æ®ï¼Œæ™ºèƒ½æ¨èæœ€ä¼˜çš„ç”Ÿäº§ä¼˜åŒ–å‚æ•°</p>
            <p><strong>è¾“å…¥ï¼š</strong>é”€å”®æ•°æ®ç‰¹å¾ï¼ˆæ€»é”€é‡ã€å¹³å‡é”€é‡ã€è¶‹åŠ¿ç­‰ï¼‰</p>
            <p><strong>è¾“å‡ºï¼š</strong>æ¨èçš„åˆ©æ¶¦å‚æ•°ã€åŸæ–™é™åˆ¶ã€è¿è¾“é™åˆ¶ã€ç”Ÿäº§çº¦æŸ</p>
            <p><strong>åº”ç”¨åœºæ™¯ï¼š</strong>è‡ªåŠ¨åŒ–å‚æ•°è°ƒä¼˜ã€å‡å°‘äººå·¥å†³ç­–æ—¶é—´ã€æé«˜ä¼˜åŒ–æ•ˆç‡</p>
        </div>
        """, unsafe_allow_html=True)

    # æ•°æ®æ¥æºé€‰æ‹©
    st.markdown("### ğŸ“Š é€‰æ‹©æ•°æ®æ¥æº")
    data_source = st.radio(
        "è¯·é€‰æ‹©è®­ç»ƒæ•°æ®æ¥æºï¼š",
        ["ğŸ² ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®", "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®"],
        key="lightgbm_data_source",
        horizontal=True
    )

    col1, col2 = st.columns([2, 1])

    with col1:
        if data_source == "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®":
            # æ•°æ®ä¸Šä¼ åŒºåŸŸ
            st.markdown("### ğŸ“ ä¸Šä¼ è®­ç»ƒæ•°æ®")
            st.info("""
            **æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
            - CSV æ–‡ä»¶æ ¼å¼ï¼Œé¦–åˆ—ä¸ºåœºæ™¯ç´¢å¼•
            - **è¾“å…¥ç‰¹å¾åˆ—ï¼š**
              - å„é¥®æ–™7å¤©æ€»é”€é‡ï¼ˆå¦‚ï¼šç¢³é…¸é¥®æ–™_7å¤©æ€»é”€é‡ï¼‰
              - å„åœ°åŒºé”€é‡å æ¯”ï¼ˆå¦‚ï¼šç¢³é…¸é¥®æ–™_é“é‡ŒåŒº_å æ¯”ï¼‰
              - è¶‹åŠ¿å’Œå­£èŠ‚æ€§å› å­
            - **è¾“å‡ºæ ‡ç­¾åˆ—ï¼š**
              - æ¨èåˆ©æ¶¦å‚æ•°ã€åŸæ–™ä¾›åº”é™åˆ¶
              - è¿è¾“é™åˆ¶ã€ç”Ÿäº§çº¦æŸå‚æ•°
            - è¯¦è§æ•°æ®æ¨¡æ¿
            """)

            uploaded_file = st.file_uploader(
                "é€‰æ‹© CSV æ–‡ä»¶ä¸Šä¼ ",
                type=['csv'],
                key="lightgbm_upload",
                help="ä¸Šä¼ åŒ…å«ç‰¹å¾å’Œæ ‡ç­¾çš„è®­ç»ƒæ•°æ®"
            )

            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
                    st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…± {len(df)} æ¡è®°å½•")
                    st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                    st.dataframe(df.head(10), use_container_width=True)
                    st.session_state['lightgbm_data'] = df
                    st.session_state['lightgbm_data_ready'] = True
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
                    st.session_state['lightgbm_data_ready'] = False
            else:
                st.warning("âš ï¸ è¯·ä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶")
                st.session_state['lightgbm_data_ready'] = False

        else:  # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            st.markdown("### ğŸ² æ¨¡æ‹Ÿæ•°æ®è®¾ç½®")
            st.info("ç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆç¬¦åˆæ¨¡å‹è¦æ±‚çš„æ¨¡æ‹Ÿç‰¹å¾å’Œæ ‡ç­¾æ•°æ®ç”¨äºè®­ç»ƒã€‚")

            n_samples = st.slider("ç”Ÿæˆæ ·æœ¬æ•°é‡", 1000, 10000, 3000, 500, key="l_samples")

            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
            if 'lightgbm_data' in st.session_state and st.session_state.get('lightgbm_data_source_type') == 'simulated':
                st.success(f"âœ… å·²å‡†å¤‡ {len(st.session_state['lightgbm_data'])} æ¡æ¨¡æ‹Ÿæ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(st.session_state['lightgbm_data'].head(10), use_container_width=True)

            if st.button("ğŸ”„ é¢„è§ˆ/åˆ·æ–°æ¨¡æ‹Ÿæ•°æ®", key="preview_lightgbm_data"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®..."):
                    from lightgbm_data_processor import LightGBMDataGenerator
                    generator = LightGBMDataGenerator()
                    X, y = generator.generate_training_data(n_samples)

                    # åˆå¹¶ä¸º DataFrame
                    feature_names = generator.get_feature_names()
                    target_names = generator.get_target_names()

                    df_features = pd.DataFrame(X, columns=feature_names)
                    df_targets = pd.DataFrame(y, columns=target_names)
                    df = pd.concat([df_features, df_targets], axis=1)

                    st.session_state['lightgbm_data'] = df
                    st.session_state['lightgbm_X'] = X
                    st.session_state['lightgbm_y'] = y
                    st.session_state['lightgbm_feature_names'] = feature_names
                    st.session_state['lightgbm_target_names'] = target_names
                    st.session_state['lightgbm_data_source_type'] = 'simulated'
                    st.session_state['lightgbm_n_samples'] = n_samples
                    st.rerun()

            # æ¨¡æ‹Ÿæ•°æ®å§‹ç»ˆå¯ç”¨
            st.session_state['lightgbm_data_ready'] = True

    with col2:
        # ä¸‹è½½æ¨¡æ¿
        st.markdown("### ğŸ“¥ æ•°æ®æ¨¡æ¿ä¸‹è½½")
        template_df = generate_lightgbm_template()
        csv_data = convert_df_to_csv(template_df, include_index=True)  # åŒ…å«åœºæ™¯ç´¢å¼•

        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½æ•°æ®æ¨¡æ¿",
            data=csv_data,
            file_name="lightgbm_data_template.csv",
            mime="text/csv",
            use_container_width=True
        )

        st.markdown("**æ¨¡æ¿é¢„è§ˆï¼š**")
        st.dataframe(template_df.head(5), use_container_width=True)

        # è®­ç»ƒå‚æ•°
        st.markdown("### âš™ï¸ è®­ç»ƒå‚æ•°")
        n_estimators = st.number_input("æ ‘çš„æ•°é‡", 50, 500, 200, 50, key="l_estimators")
        max_depth = st.number_input("æœ€å¤§æ·±åº¦", 3, 15, 8, 1, key="l_depth")
        learning_rate = st.select_slider("å­¦ä¹ ç‡", [0.01, 0.03, 0.05, 0.1], value=0.05, key="l_lr")

    # å¼€å§‹è®­ç»ƒæŒ‰é’®
    st.markdown("---")
    st.markdown("### ğŸš€ å¼€å§‹è®­ç»ƒ")

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ¯ å¼€å§‹è®­ç»ƒ LightGBM æ¨¡å‹", key="start_lightgbm_training",
                     use_container_width=True, type="primary"):
            if not LIGHTGBM_AVAILABLE:
                st.error("âŒ LightGBM æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install lightgbm")
            elif data_source == "ğŸ“ ä¸Šä¼ è‡ªå®šä¹‰æ•°æ®":
                # ä½¿ç”¨ä¸Šä¼ æ•°æ®æ¨¡å¼
                if not st.session_state.get('lightgbm_data_ready', False) or 'lightgbm_data' not in st.session_state:
                    st.error("âŒ è¯·å…ˆä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶")
                else:
                    train_lightgbm_with_progress(n_estimators, max_depth, learning_rate)
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼ - è‡ªåŠ¨ç”Ÿæˆæ•°æ®
                with st.spinner("æ­£åœ¨å‡†å¤‡æ¨¡æ‹Ÿæ•°æ®..."):
                    from lightgbm_data_processor import LightGBMDataGenerator
                    generator = LightGBMDataGenerator()
                    n_samples_val = st.session_state.get('lightgbm_n_samples', 3000)
                    X, y = generator.generate_training_data(n_samples_val)

                    feature_names = generator.get_feature_names()
                    target_names = generator.get_target_names()

                    df_features = pd.DataFrame(X, columns=feature_names)
                    df_targets = pd.DataFrame(y, columns=target_names)
                    df = pd.concat([df_features, df_targets], axis=1)

                    st.session_state['lightgbm_data'] = df
                    st.session_state['lightgbm_X'] = X
                    st.session_state['lightgbm_y'] = y
                    st.session_state['lightgbm_feature_names'] = feature_names
                    st.session_state['lightgbm_target_names'] = target_names
                    st.session_state['lightgbm_data_source_type'] = 'simulated'

                train_lightgbm_with_progress(n_estimators, max_depth, learning_rate)


def train_lightgbm_with_progress(n_estimators, max_depth, learning_rate):
    """å¸¦è¿›åº¦æ¡çš„ LightGBM è®­ç»ƒ"""
    from lightgbm_model import ParameterRecommender
    from lightgbm_data_processor import LightGBMDataGenerator

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    st.markdown("### ğŸ“ˆ è®­ç»ƒè¿›åº¦")
    progress_container = st.container()

    with progress_container:
        status_text = st.empty()
        progress_bar = st.progress(0)
        metrics_placeholder = st.empty()

    try:
        status_text.info("ğŸ”„ å‡†å¤‡æ•°æ®ä¸­...")

        # æ£€æŸ¥æ˜¯å¦æœ‰é¢„å¤„ç†çš„æ•°æ®
        if 'lightgbm_X' in st.session_state:
            X = st.session_state['lightgbm_X']
            y = st.session_state['lightgbm_y']
            feature_names = st.session_state['lightgbm_feature_names']
            target_names = st.session_state['lightgbm_target_names']
        else:
            # ä»ä¸Šä¼ çš„æ•°æ®ä¸­æå–
            df = st.session_state['lightgbm_data']
            generator = LightGBMDataGenerator()
            feature_names = generator.get_feature_names()
            target_names = generator.get_target_names()

            X = df[feature_names].values
            y = df[target_names].values

        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        n_test = int(len(X) * 0.2)
        indices = np.random.permutation(len(X))
        test_indices = indices[:n_test]
        train_indices = indices[n_test:]

        X_train, X_test = X[train_indices], X[test_indices]
        y_train, y_test = y[train_indices], y[test_indices]

        progress_bar.progress(0.1)
        status_text.info("ğŸ”„ åˆå§‹åŒ–æ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹
        recommender = ParameterRecommender()
        recommender.lgb_params.update({
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'learning_rate': learning_rate
        })

        progress_bar.progress(0.2)
        status_text.info("ğŸš€ å¼€å§‹è®­ç»ƒ...")

        # è®­ç»ƒæ¨¡å‹ï¼ˆå¸¦è¿›åº¦æ›´æ–°ï¼‰
        total_targets = len(target_names)
        metrics_list = []

        for i, target_name in enumerate(target_names):
            import lightgbm as lgb

            model = lgb.LGBMRegressor(**recommender.lgb_params)
            model.fit(X_train, y_train[:, i])
            recommender.models[target_name] = model

            # è®¡ç®— MAE
            pred = model.predict(X_test)
            mae = np.mean(np.abs(pred - y_test[:, i]))
            metrics_list.append({'ç›®æ ‡': target_name, 'MAE': mae})

            # æ›´æ–°è¿›åº¦
            progress = 0.2 + 0.7 * (i + 1) / total_targets
            progress_bar.progress(progress)
            status_text.info(f"ğŸš€ è®­ç»ƒä¸­... ({i+1}/{total_targets}) {target_name}")

            # æ›´æ–°æŒ‡æ ‡æ˜¾ç¤º
            metrics_df = pd.DataFrame(metrics_list)
            metrics_placeholder.dataframe(metrics_df, use_container_width=True)

        recommender.feature_names = feature_names
        recommender.target_names = target_names
        recommender.is_fitted = True

        progress_bar.progress(0.95)
        status_text.info("ğŸ”„ ä¿å­˜æ¨¡å‹...")

        # ä¿å­˜æ¨¡å‹
        os.makedirs('./data', exist_ok=True)
        recommender.save_model('./data')

        progress_bar.progress(1.0)
        status_text.empty()
        progress_bar.empty()

        avg_mae = np.mean([m['MAE'] for m in metrics_list])
        st.success(f"""
        âœ… **è®­ç»ƒå®Œæˆï¼**
        - å¹³å‡ MAE: {avg_mae:.4f}
        - æ¨¡å‹å·²ä¿å­˜è‡³: ./data/
        """)
        st.balloons()

    except Exception as e:
        st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")


# ==================== æ™ºèƒ½å‚æ•°ä¼˜åŒ–é¡µé¢ ====================

def page_smart_optimization(optimization_model):
    """æ™ºèƒ½å‚æ•°ä¼˜åŒ–é¡µé¢"""
    st.markdown("# ğŸ§  æ™ºèƒ½å‚æ•°ä¼˜åŒ–")
    st.markdown("---")

    # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
    if not TORCH_AVAILABLE:
        st.warning("âš ï¸ PyTorch æœªå®‰è£…ï¼Œæ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨")
        st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š`pip install torch`")
        st.markdown("---")
        st.markdown("### ğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ")
        st.markdown("æ‚¨å¯ä»¥ä½¿ç”¨ä¾§è¾¹æ çš„ **å‚æ•°è®¾ç½®** æ‰‹åŠ¨è°ƒæ•´ä¼˜åŒ–å‚æ•°ï¼Œç„¶ååœ¨ä¸»é¡µç‚¹å‡»ã€Œå¼€å§‹æ±‚è§£ã€ã€‚")
        return

    if not LIGHTGBM_AVAILABLE:
        st.warning("âš ï¸ LightGBM æœªå®‰è£…ï¼Œæ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨")
        st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š`pip install lightgbm`")
        st.markdown("---")
        st.markdown("### ğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ")
        st.markdown("æ‚¨å¯ä»¥ä½¿ç”¨ä¾§è¾¹æ çš„ **å‚æ•°è®¾ç½®** æ‰‹åŠ¨è°ƒæ•´ä¼˜åŒ–å‚æ•°ï¼Œç„¶ååœ¨ä¸»é¡µç‚¹å‡»ã€Œå¼€å§‹æ±‚è§£ã€ã€‚")
        return

    # åŠŸèƒ½ä»‹ç»
    with st.container():
        st.markdown("""
        <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
                    padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;">
            <h3>ğŸ“Œ åŠŸèƒ½è¯´æ˜</h3>
            <p><strong>å·¥ä½œåŸç†ï¼š</strong></p>
            <ol>
                <li>Transformer æ¨¡å‹é¢„æµ‹æœªæ¥7å¤©çš„é”€å”®æ•°æ®</li>
                <li>LightGBM æ¨¡å‹æ ¹æ®é¢„æµ‹æ•°æ®æ¨èæœ€ä¼˜å‚æ•°</li>
                <li>ç”¨æˆ·å¯é€‰æ‹©å°†æ¨èå‚æ•°åŒæ­¥åˆ°ä¼˜åŒ–æ¨¡å‹</li>
            </ol>
        </div>
        """, unsafe_allow_html=True)

    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    status = check_model_status()

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### ğŸ“‹ æ¨¡å‹çŠ¶æ€æ£€æŸ¥")
        if status['transformer_model']:
            st.success("âœ… Transformer æ¨¡å‹å·²å°±ç»ª")
        else:
            st.info("â„¹ï¸ Transformer æ¨¡å‹æœªè®­ç»ƒ")
            st.caption("è¯·å…ˆåœ¨ã€Œæ¨¡å‹è®­ç»ƒã€ä¸­è®­ç»ƒ Transformer æ¨¡å‹")

    with col2:
        st.markdown("###  ")  # å ä½
        if status['lightgbm_model']:
            st.success("âœ… LightGBM æ¨¡å‹å·²å°±ç»ª")
        else:
            st.info("â„¹ï¸ LightGBM æ¨¡å‹æœªè®­ç»ƒ")
            st.caption("è¯·å…ˆåœ¨ã€Œæ¨¡å‹è®­ç»ƒã€ä¸­è®­ç»ƒ LightGBM æ¨¡å‹")

    models_ready = status['transformer_model'] and status['lightgbm_model']

    if not models_ready:
        st.markdown("---")
        st.markdown("### ğŸ“ è®­ç»ƒæŒ‡å—")
        st.markdown("""
        è¦ä½¿ç”¨æ™ºèƒ½å‚æ•°ä¼˜åŒ–ï¼Œè¯·æŒ‰ä»¥ä¸‹é¡ºåºè®­ç»ƒæ¨¡å‹ï¼š

        1. **è®­ç»ƒ Transformer æ¨¡å‹**ï¼šç”¨äºé¢„æµ‹æœªæ¥é”€å”®æ•°æ®
        2. **è®­ç»ƒ LightGBM æ¨¡å‹**ï¼šç”¨äºæ ¹æ®é¢„æµ‹æ¨èæœ€ä¼˜å‚æ•°

        è®­ç»ƒå®Œæˆåï¼Œå³å¯ä½¿ç”¨æ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½è‡ªåŠ¨æ¨èå‚æ•°ã€‚
        """)

        # æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ—§æ¨èç»“æœ
        if 'recommendations' in st.session_state:
            del st.session_state['recommendations']

        # æä¾›å¿«é€Ÿå¯¼èˆªæŒ‰é’®
        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤– è®­ç»ƒ Transformer", key="goto_transformer", use_container_width=True):
                st.session_state.current_page = 'transformer_training'
                st.session_state.training_model_expanded = True
                st.rerun()
        with col2:
            if st.button("ğŸ“Š è®­ç»ƒ LightGBM", key="goto_lightgbm", use_container_width=True):
                st.session_state.current_page = 'lightgbm_training'
                st.session_state.training_model_expanded = True
                st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ")
        st.markdown("åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆå‰ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¾§è¾¹æ çš„ **å‚æ•°è®¾ç½®** æ‰‹åŠ¨è°ƒæ•´å‚æ•°ã€‚")
        return

    st.markdown("---")

    # ä¼˜åŒ–æŒ‰é’®
    st.markdown("### ğŸš€ å¼€å§‹æ™ºèƒ½ä¼˜åŒ–")

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ¯ å¼€å§‹æ™ºèƒ½å‚æ•°ä¼˜åŒ–", key="start_smart_opt",
                     use_container_width=True, type="primary"):
            run_smart_optimization()

    # æ˜¾ç¤ºä¼˜åŒ–ç»“æœï¼ˆåªæœ‰åœ¨æ¨¡å‹å‡†å¤‡å¥½çš„æƒ…å†µä¸‹æ‰æ˜¾ç¤ºï¼‰
    if st.session_state.get('recommendations'):
        display_optimization_results(optimization_model)


def run_smart_optimization():
    """æ‰§è¡Œæ™ºèƒ½ä¼˜åŒ–"""
    import torch
    from transformer_model import SalesForecasterEncoderOnly
    from sales_data_processor import SalesDataProcessor, SalesDataGenerator
    from lightgbm_model import ParameterRecommender, SalesFeatureExtractor

    st.markdown("### ğŸ“ˆ ä¼˜åŒ–è¿›åº¦")
    progress_container = st.container()

    with progress_container:
        status_text = st.empty()
        progress_bar = st.progress(0)

    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # æ­¥éª¤1: åŠ è½½ Transformer æ¨¡å‹
        status_text.info("ğŸ”„ åŠ è½½ Transformer æ¨¡å‹...")
        progress_bar.progress(0.1)

        transformer = SalesForecasterEncoderOnly(
            input_dim=5, d_model=128, num_heads=8, num_layers=4,
            d_ff=512, input_seq_len=30, output_seq_len=7, dropout=0.1
        )
        transformer.load_state_dict(torch.load('./data/best_transformer_model.pth', map_location=device))
        transformer = transformer.to(device)
        transformer.eval()

        # æ­¥éª¤2: åŠ è½½æ•°æ®å¤„ç†å™¨
        status_text.info("ğŸ”„ åŠ è½½æ•°æ®å¤„ç†å™¨...")
        progress_bar.progress(0.2)

        processor = SalesDataProcessor()
        processor.load_scaler('./data/scaler_params.npz')

        # æ­¥éª¤3: ç”Ÿæˆè¾“å…¥æ•°æ®
        status_text.info("ğŸ”„ å‡†å¤‡è¾“å…¥æ•°æ®...")
        progress_bar.progress(0.3)

        generator = SalesDataGenerator()
        df = generator.generate_sales_data(num_days=30, start_date='2025-01-01')
        recent_data = df[generator.beverage_types].values

        # æ­¥éª¤4: Transformer é¢„æµ‹
        status_text.info("ğŸ”® æ‰§è¡Œé”€å”®é¢„æµ‹...")
        progress_bar.progress(0.5)

        normalized_input = processor.transform(recent_data)
        x = torch.FloatTensor(normalized_input).unsqueeze(0).to(device)

        with torch.no_grad():
            pred = transformer(x)
            pred = pred.squeeze(0).cpu().numpy()

        predictions = processor.inverse_transform(pred)

        # æ­¥éª¤5: åŠ è½½ LightGBM æ¨¡å‹
        status_text.info("ğŸ”„ åŠ è½½ LightGBM æ¨¡å‹...")
        progress_bar.progress(0.7)

        recommender = ParameterRecommender()
        recommender.load_model('./data')

        # æ­¥éª¤6: æ¨èå‚æ•°
        status_text.info("ğŸ§  ç”Ÿæˆå‚æ•°æ¨è...")
        progress_bar.progress(0.9)

        extractor = SalesFeatureExtractor()
        features = extractor.extract_features(predictions).reshape(1, -1)
        pred_params = recommender.predict_dict(features)

        # æ•´ç†åŸå§‹é¢„æµ‹ç»“æœ
        beverage_types = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']
        material_types = ['ç™½ç ‚ç³–', 'æµ“ç¼©æœæ±', 'èŒ¶å¶æå–ç‰©', 'åŠŸèƒ½æˆåˆ†', 'åŒ…è£…ææ–™']
        regions = ['é“é‡ŒåŒº', 'å—å²—åŒº', 'é“å¤–åŒº', 'é¦™åŠåŒº', 'æ¾åŒ—åŒº']

        raw_result = {
            'profits': {bev: float(pred_params['profits'][0, i])
                       for i, bev in enumerate(beverage_types)},
            'material_limits': {mat: float(pred_params['material_limits'][0, i])
                               for i, mat in enumerate(material_types)},
            'transport_limits': {reg: float(pred_params['transport_limits'][0, i])
                                for i, reg in enumerate(regions)},
            'min_production_ratio': float(pred_params['min_production_ratio'][0]),
            'max_production_multiplier': float(pred_params['max_production_multiplier'][0])
        }

        # è£å‰ªå‚æ•°åˆ°æ¨¡å‹å…è®¸çš„èŒƒå›´å†…
        status_text.info("ğŸ”§ æ ¡éªŒå‚æ•°èŒƒå›´...")
        clipped_params = clip_params_to_limits(raw_result)

        result = {
            'predictions': predictions,
            'profits': clipped_params['profits'],
            'material_limits': clipped_params['material_limits'],
            'transport_limits': clipped_params['transport_limits'],
            'min_production_ratio': clipped_params['min_production_ratio'],
            'max_production_multiplier': clipped_params['max_production_multiplier']
        }

        st.session_state['recommendations'] = result

        progress_bar.progress(1.0)
        status_text.empty()
        progress_bar.empty()

        st.success("âœ… æ™ºèƒ½ä¼˜åŒ–å®Œæˆï¼")
        st.rerun()

    except Exception as e:
        status_text.empty()
        progress_bar.empty()
        st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}")


def display_optimization_results(optimization_model):
    """æ˜¾ç¤ºä¼˜åŒ–ç»“æœå¹¶æä¾›åŒæ­¥é€‰é¡¹"""
    result = st.session_state['recommendations']
    predictions = result['predictions']
    beverage_types = ['ç¢³é…¸é¥®æ–™', 'æœæ±é¥®æ–™', 'èŒ¶é¥®æ–™', 'åŠŸèƒ½é¥®æ–™', 'çŸ¿æ³‰æ°´']

    st.markdown("---")
    st.markdown("## ğŸ“Š ä¼˜åŒ–ç»“æœ")

    # é”€å”®é¢„æµ‹
    st.markdown("### ğŸ“ˆ æœªæ¥7å¤©é”€å”®é¢„æµ‹")

    col1, col2 = st.columns([2, 1])

    with col1:
        # é¢„æµ‹å›¾è¡¨
        fig = go.Figure()
        colors = ['#2E8B57', '#4682B4', '#DAA520', '#CD853F', '#708090']

        for i, (bev, color) in enumerate(zip(beverage_types, colors)):
            fig.add_trace(go.Scatter(
                x=list(range(1, 8)),
                y=predictions[:, i],
                mode='lines+markers',
                name=bev,
                line=dict(color=color, width=2),
                marker=dict(size=8)
            ))

        fig.update_layout(
            xaxis_title="å¤©æ•°",
            yaxis_title="é”€é‡ (å‡)",
            height=350,
            legend=dict(orientation="h", yanchor="bottom", y=1.02)
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown("**é¢„æµ‹æ±‡æ€»**")
        for i, bev in enumerate(beverage_types):
            total = np.sum(predictions[:, i])
            st.metric(bev, f"{total:,.0f} å‡", f"æ—¥å‡ {total/7:,.0f}")

    # æ¨èå‚æ•°
    st.markdown("### ğŸ¯ æ¨èå‚æ•°")

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’° åˆ©æ¶¦å‚æ•°", "ğŸ“¦ åŸæ–™é™åˆ¶", "ğŸš› è¿è¾“é™åˆ¶", "âš™ï¸ ç”Ÿäº§çº¦æŸ"])

    with tab1:
        col1, col2 = st.columns(2)
        profits = result['profits']
        items = list(profits.items())
        for i, (bev, profit) in enumerate(items):
            with (col1 if i < 3 else col2):
                st.metric(bev, f"{profit} å…ƒ/å‡")

    with tab2:
        col1, col2 = st.columns(2)
        materials = result['material_limits']
        items = list(materials.items())
        for i, (mat, limit) in enumerate(items):
            with (col1 if i < 3 else col2):
                st.metric(mat, f"{limit:,.0f} åƒå…‹")

    with tab3:
        col1, col2 = st.columns(2)
        transport = result['transport_limits']
        items = list(transport.items())
        for i, (reg, limit) in enumerate(items):
            with (col1 if i < 3 else col2):
                st.metric(reg, f"{limit:,.0f} å‡")

    with tab4:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æœ€å°ç”Ÿäº§æ¯”ä¾‹", result['min_production_ratio'])
        with col2:
            st.metric("æœ€å¤§ç”Ÿäº§å€æ•°", result['max_production_multiplier'])

    # åŒæ­¥é€‰é¡¹
    st.markdown("---")
    st.markdown("### ğŸ”„ å‚æ•°åŒæ­¥")

    sync_option = st.radio(
        "æ˜¯å¦å°†æ¨èå‚æ•°åŒæ­¥åˆ°ä¼˜åŒ–æ¨¡å‹ï¼Ÿ",
        ["å¦ï¼Œä»…æŸ¥çœ‹æ¨èç»“æœ", "æ˜¯ï¼ŒåŒæ­¥åˆ°å‚æ•°è®¾ç½®"],
        key="sync_radio",
        horizontal=True
    )

    if sync_option == "æ˜¯ï¼ŒåŒæ­¥åˆ°å‚æ•°è®¾ç½®":
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("âœ… ç¡®è®¤åŒæ­¥å‚æ•°", key="confirm_sync", use_container_width=True, type="primary"):
                # åŒæ­¥å‚æ•°åˆ°æ¨¡å‹
                profits_list = list(result['profits'].values())
                material_limits_list = list(result['material_limits'].values())
                transport_limits_list = list(result['transport_limits'].values())

                params = {
                    'profits': profits_list,
                    'material_limits': material_limits_list,
                    'transport_limits': transport_limits_list,
                    'min_production_ratio': result['min_production_ratio'],
                    'max_production_multiplier': result['max_production_multiplier']
                }
                optimization_model.update_parameters(params)

                # åŒæ­¥æ›´æ–°ä¾§è¾¹æ çš„ session_stateï¼Œä½¿ UI æ§ä»¶æ˜¾ç¤ºæ–°å€¼
                st.session_state.sidebar_profits = profits_list
                st.session_state.sidebar_material_limits = material_limits_list
                st.session_state.sidebar_transport_limits = transport_limits_list
                st.session_state.sidebar_min_ratio = result['min_production_ratio']
                st.session_state.sidebar_max_multiplier = result['max_production_multiplier']

                # åˆ é™¤æ§ä»¶çš„ keyï¼Œè®©ä¸‹æ¬¡æ¸²æŸ“æ—¶ä» sidebar_* å˜é‡é‡æ–°è¯»å–
                # ï¼ˆStreamlit ä¸å…è®¸ç›´æ¥ä¿®æ”¹å·²å®ä¾‹åŒ–æ§ä»¶çš„ key å€¼ï¼‰
                keys_to_delete = []
                for i in range(5):
                    keys_to_delete.extend([f"profit_{i}", f"material_{i}", f"transport_{i}"])
                keys_to_delete.extend(["min_ratio", "max_multiplier"])

                for key in keys_to_delete:
                    if key in st.session_state:
                        del st.session_state[key]

                st.session_state['sync_params'] = True
                st.session_state['sync_success'] = True  # æ ‡è®°åŒæ­¥æˆåŠŸï¼Œç”¨äºæ˜¾ç¤ºæç¤º
                st.rerun()

    # åœ¨é¡µé¢é‡æ–°æ¸²æŸ“åæ˜¾ç¤ºåŒæ­¥æˆåŠŸæç¤º
    if st.session_state.get('sync_success', False):
        st.success("âœ… å‚æ•°å·²åŒæ­¥æˆåŠŸï¼ä¾§è¾¹æ å‚æ•°å·²æ›´æ–°ï¼Œè¯·è¿”å›ä¸»é¡µç‚¹å‡»ã€Œå¼€å§‹æ±‚è§£ã€æŸ¥çœ‹ä¼˜åŒ–ç»“æœã€‚")
        st.balloons()
        st.session_state['sync_success'] = False  # é‡ç½®çŠ¶æ€ï¼Œåªæ˜¾ç¤ºä¸€æ¬¡


# ==================== ä¸»è·¯ç”±å‡½æ•° ====================

def render_ml_page(optimization_model):
    """æ ¹æ®å½“å‰é¡µé¢çŠ¶æ€æ¸²æŸ“å¯¹åº”é¡µé¢"""
    init_session_state()

    current_page = st.session_state.get('current_page', 'main')

    if current_page == 'transformer_training':
        page_transformer_training()
        return True
    elif current_page == 'lightgbm_training':
        page_lightgbm_training()
        return True
    elif current_page == 'smart_optimization':
        page_smart_optimization(optimization_model)
        return True

    return False
